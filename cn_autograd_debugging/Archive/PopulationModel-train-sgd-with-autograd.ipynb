{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to implement population model gradient descent to learn parametesr such as p_sympt, p_severe, p_hosp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/cuongnguyen/Desktop/cn_autograd_debugging/Archive/merged_data.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/cuongnguyen/Desktop/cn_autograd_debugging/Archive/merged_data.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.106171 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.106171 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[int,int,int,int,int,int,str,int,str,int,int,int,float]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/cuongnguyen/Desktop/cn_autograd_debugging/Archive/merged_data.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/cuongnguyen/Desktop/cn_autograd_debugging/Archive/merged_data.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 19520 lines in 0.048223 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 19520 lines in 0.048223 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/cuongnguyen/Desktop/cn_autograd_debugging/Archive/covidestim.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/cuongnguyen/Desktop/cn_autograd_debugging/Archive/covidestim.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.333283 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.333283 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/cuongnguyen/Desktop/cn_autograd_debugging/Archive/covidestim.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/cuongnguyen/Desktop/cn_autograd_debugging/Archive/covidestim.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 21916 lines in 0.198203 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 21916 lines in 0.198203 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/cuongnguyen/Desktop/cn_autograd_debugging/Archive/CA_forecast_after_20201010.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/cuongnguyen/Desktop/cn_autograd_debugging/Archive/CA_forecast_after_20201010.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 92 lines in 0.034466 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 92 lines in 0.034466 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,int,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,str,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/cuongnguyen/Desktop/cn_autograd_debugging/Archive/CA_forecast_after_20201010.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/cuongnguyen/Desktop/cn_autograd_debugging/Archive/CA_forecast_after_20201010.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 92 lines in 0.009699 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 92 lines in 0.009699 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/cuongnguyen/Desktop/cn_autograd_debugging/Archive/covidestim.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/cuongnguyen/Desktop/cn_autograd_debugging/Archive/covidestim.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.176881 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.176881 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/cuongnguyen/Desktop/cn_autograd_debugging/Archive/covidestim.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/cuongnguyen/Desktop/cn_autograd_debugging/Archive/covidestim.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 21916 lines in 0.192645 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 21916 lines in 0.192645 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "import turicreate as tc\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "state_long = 'California'\n",
    "state_short = 'CA' \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from PopulationData_ag import PopulationData\n",
    "from HospitalData_v20210203 import HospitalData\n",
    "# # import random\n",
    "import autograd\n",
    "\n",
    "\n",
    "hd_truthful = HospitalData('merged_data.csv', state_short,'20200711','20210305')\n",
    "pd_truthful = PopulationData('covidestim.csv', state_long,'20200711', '20210305', forecast=False);\n",
    "\n",
    "# this list is a list of len 1 since we are not doing mini batches\n",
    "pd_list_train = [PopulationData(state_short+ '_forecast_after_'+str(20201010) + '.csv',state_long,'20200711',str(20201021), training_mode=True, debug_mode=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567.1823638466446 at iteration  0\n",
      "552.2326386661564 at iteration  1\n",
      "537.3644899857845 at iteration  2\n",
      "522.5774274485709 at iteration  3\n",
      "507.87096378076876 at iteration  4\n"
     ]
    }
   ],
   "source": [
    "def get_truthdict_given_mid_end(mid_date,end_date):\n",
    "#     print(mid_date,end_date, 'mid date end date')\n",
    "    pd_truthful.start_date = mid_date\n",
    "    pd_truthful.end_date = end_date\n",
    "    hd_truthful.start_date = mid_date\n",
    "    hd_truthful.end_date = end_date\n",
    "    truthdict = {\n",
    "    'date':pd_truthful.filtered_data['date'],\n",
    "    'infections':pd_truthful.filtered_data['infections'],\n",
    "    'symptomatic':pd_truthful.filtered_data['symptomatic'],\n",
    "    'severe':pd_truthful.filtered_data['severe'],\n",
    "    'hosp':hd_truthful.filtered_data['previous_day_admission_adult_covid_confirmed'],\n",
    "    }\n",
    "\n",
    "    return truthdict\n",
    "\n",
    "\n",
    "def add_to_dict(d,g):\n",
    "    for k in d.keys():\n",
    "        d[k]=d[k]+g[k]\n",
    "    return d\n",
    "\n",
    "def scale_dict_vals(d,s):\n",
    "    for k in d.keys():\n",
    "        d[k] = s*d[k]\n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "def gradient_descent(pd_list_train, init_params, n_iters=2, step_size=0.001, n_steps_between_print=5, lambda_reg = 1, epsilon_stop=5e-10):\n",
    "    batch_loss_per_iteration = []\n",
    "    for n in range(n_iters):\n",
    "        batch_loss = 0\n",
    "        for pd in pd_list_train: \n",
    "            pd.loss_per_iteration += [0]\n",
    "        \n",
    "        pd_batch = random.choice(pd_list_train,replace=False, size=1) # in this case, there is only 1 training duration\n",
    "        if n == 0:\n",
    "            new_params = init_params\n",
    "        else:\n",
    "            new_params = add_to_dict(new_params, scale_dict_vals(grads, -1*step_size))\n",
    "        \n",
    "        \n",
    "        for i,pd in enumerate(pd_batch): # in this case, there is only 1 training duration\n",
    "            pd.training_mode=True\n",
    "            new_grad = pd.get_grad_of_loss(new_params,get_truthdict_given_mid_end(pd.filtered_data['date'][-1], pd.end_date) ,lambda_reg= lambda_reg)\n",
    "            batch_loss += pd.loss_per_iteration[-1] \n",
    "            if i == 0:\n",
    "                grads = new_grad\n",
    "            else:\n",
    "                grads = add_to_dict(grads, new_grad)\n",
    "        \n",
    "        grads = scale_dict_vals(grads, 1/len(pd_batch))\n",
    "        batch_loss_per_iteration += [batch_loss/len(pd_batch)]\n",
    "        print(batch_loss/len(pd_batch), 'at iteration ', n)\n",
    "\n",
    "    return new_params, batch_loss_per_iteration\n",
    "\n",
    "train_params = {'T_serial':5.8,'prob_sympt':0.82,'prob_severe':0.2,'prob_hosp':0.25,'prob_soujourn_inf_alpha':3.41, 'prob_soujourn_inf_beta':0.605,'prob_soujourn_symp_alpha':1.62, 'prob_soujourn_symp_beta':0.218}\n",
    "new_params = gradient_descent(\n",
    "    pd_list_train, train_params, n_iters=5, step_size=5e-8, n_steps_between_print=5, lambda_reg=1,epsilon_stop=5e-8)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
