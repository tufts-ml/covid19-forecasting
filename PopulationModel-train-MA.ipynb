{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to implement population model gradient descent to learn parametesr such as p_sympt, p_severe, p_hosp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/cuongnguyen/Desktop/pop_cv19/covidestim.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/cuongnguyen/Desktop/pop_cv19/covidestim.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.183209 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.183209 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/cuongnguyen/Desktop/pop_cv19/covidestim.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/cuongnguyen/Desktop/pop_cv19/covidestim.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 16744 lines in 0.365033 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 16744 lines in 0.365033 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/cuongnguyen/Desktop/pop_cv19/covidestim.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/cuongnguyen/Desktop/pop_cv19/covidestim.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.338542 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.338542 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/cuongnguyen/Desktop/pop_cv19/covidestim.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/cuongnguyen/Desktop/pop_cv19/covidestim.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 16744 lines in 0.303678 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 16744 lines in 0.303678 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/cuongnguyen/Desktop/pop_cv19/covidestim.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/cuongnguyen/Desktop/pop_cv19/covidestim.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.369492 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.369492 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/cuongnguyen/Desktop/pop_cv19/covidestim.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/cuongnguyen/Desktop/pop_cv19/covidestim.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 16744 lines in 0.262884 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 16744 lines in 0.262884 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/cuongnguyen/Desktop/pop_cv19/data/MA_forecast_after_20210501.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/cuongnguyen/Desktop/pop_cv19/data/MA_forecast_after_20210501.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 0 lines in 0.03005 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 0 lines in 0.03005 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insufficient number of rows to perform type inference\n",
      "Could not detect types. Using str for each column.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/cuongnguyen/Desktop/pop_cv19/data/MA_forecast_after_20210501.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/cuongnguyen/Desktop/pop_cv19/data/MA_forecast_after_20210501.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 0 lines in 0.007972 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 0 lines in 0.007972 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Type of given values (<class 'int'>) does not match type of column 'selected_row' (<class 'float'>) in SFrame.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fe22b03159ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mpd_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_mid_dates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_end_dates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mpd_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mPopulationData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstate_short\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'_forecast_after_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_long\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'20210101'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/pop_cv19/PopulationData_ag_interpRT.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, csv_filename, us_state, start_date, end_date, forecast, params, debug_mode, training_mode, params_for_training)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_csv_if_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiltered_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_filtered_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# captures the time interval from start_date to latest estimates.csv dates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/pop_cv19/PopulationData_ag_interpRT.py\u001b[0m in \u001b[0;36mget_filtered_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# returns Sframe within specified [self.start_date, self.end_date] and self.us_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selected_row'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mus_state\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_date\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#1 means row selected, 0 means row not selected for filtered data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'selected_row'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_forecasted_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_admissions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/pop_cv19/env/lib/python3.8/site-packages/turicreate/data_structures/sframe.py\u001b[0m in \u001b[0;36mfilter_by\u001b[0;34m(self, values, column_name, exclude)\u001b[0m\n\u001b[1;32m   4750\u001b[0m         \u001b[0mgiven_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_sf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgiven_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexisting_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4752\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m   4753\u001b[0m                 (\n\u001b[1;32m   4754\u001b[0m                     \u001b[0;34m\"Type of given values ({0}) does not match type of column '\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Type of given values (<class 'int'>) does not match type of column 'selected_row' (<class 'float'>) in SFrame."
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import turicreate as tc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "covidestim_csv = 'covidestim.csv'\n",
    "# estimates = tc.SFrame(covidestim_csv)\n",
    "# print(estimates['state'].unique())\n",
    "state_long = 'Massachusetts'\n",
    "state_short = 'MA' \n",
    "\n",
    "results_folder = 'results/'\n",
    "data_folder = 'data/'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from PopulationData_ag_before_conv import PopulationData\n",
    "from PopulationData_ag_interpRT import PopulationData\n",
    "from HospitalData import HospitalData\n",
    "# import random\n",
    "import autograd\n",
    "\n",
    "\n",
    "RELOADING_RESULTS = False\n",
    "\n",
    "training_mid_dates = [20210501,  20210501] # start mid end, where forecasting happens from mid to end\n",
    "# training_mid_dates = [20201010,  20201120] # start mid end, where forecasting happens from mid to end\n",
    "forecast_duration = 25\n",
    "training_end_dates = [int((datetime.datetime.strptime(str(d),'%Y%m%d') \n",
    "                       + datetime.timedelta(days = forecast_duration)).strftime('%Y%m%d')) for d in training_mid_dates]\n",
    "\n",
    "\n",
    "# print(training_end_dates)\n",
    "def make_forecastable_csv(date):\n",
    "    pd_dummy = PopulationData(data_folder+covidestim_csv, state_long,'20210101', date, forecast=False);\n",
    "    pd_dummy.filtered_data.save(data_folder+state_short+ '_forecast_after_' + str(date) + '.csv', format='csv') \n",
    "\n",
    "hd_truthful = HospitalData('HHS_data_selective.csv', state_short,'20210101','20210601')\n",
    "pd_truthful = PopulationData(data_folder+covidestim_csv, state_long,'20210101', '20210601', forecast=False);\n",
    "# pd_truthful.filtered_data['date'].unique().sort()[-10:-1]\n",
    "\n",
    "if not RELOADING_RESULTS:\n",
    "    for d in training_mid_dates:\n",
    "        make_forecastable_csv(d)\n",
    "\n",
    "pd_list = []\n",
    "for i,(m,e) in enumerate(zip(training_mid_dates,training_end_dates)):\n",
    "    pd_list += [PopulationData(data_folder+state_short+ '_forecast_after_'+str(m) + '.csv',state_long,'20210101',str(e), training_mode=True, debug_mode=True)]\n",
    "\n",
    "\n",
    "\n",
    "pd_list_train = pd_list[0:-1]\n",
    "pd_list_val = pd_list[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">date</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">state</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">previous_day_admission_ad<br>ult_covid_confirmed ...</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">previous_day_admission_ad<br>ult_covid_confirmed_c ...</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">selected_row</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">20210101</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MA</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">309</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">101</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">20210102</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MA</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">255</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">101</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">20210103</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MA</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">267</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">101</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">20210104</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MA</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">229</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">79</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">20210105</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MA</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">325</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">79</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">20210106</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MA</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">280</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">102</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">20210107</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MA</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">297</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">102</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">20210108</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MA</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">282</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">102</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">20210109</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MA</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">269</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">102</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">20210110</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MA</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">228</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">102</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[152 rows x 5 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tdate\tstr\n",
       "\tstate\tstr\n",
       "\tprevious_day_admission_adult_covid_confirmed\tint\n",
       "\tprevious_day_admission_adult_covid_confirmed_coverage\tint\n",
       "\tselected_row\tint\n",
       "\n",
       "Rows: 152\n",
       "\n",
       "Data:\n",
       "+----------+-------+-------------------------------+-------------------------------+\n",
       "|   date   | state | previous_day_admission_adu... | previous_day_admission_adu... |\n",
       "+----------+-------+-------------------------------+-------------------------------+\n",
       "| 20210101 |   MA  |              309              |              101              |\n",
       "| 20210102 |   MA  |              255              |              101              |\n",
       "| 20210103 |   MA  |              267              |              101              |\n",
       "| 20210104 |   MA  |              229              |               79              |\n",
       "| 20210105 |   MA  |              325              |               79              |\n",
       "| 20210106 |   MA  |              280              |              102              |\n",
       "| 20210107 |   MA  |              297              |              102              |\n",
       "| 20210108 |   MA  |              282              |              102              |\n",
       "| 20210109 |   MA  |              269              |              102              |\n",
       "| 20210110 |   MA  |              228              |              102              |\n",
       "+----------+-------+-------------------------------+-------------------------------+\n",
       "+--------------+\n",
       "| selected_row |\n",
       "+--------------+\n",
       "|      1       |\n",
       "|      1       |\n",
       "|      1       |\n",
       "|      1       |\n",
       "|      1       |\n",
       "|      1       |\n",
       "|      1       |\n",
       "|      1       |\n",
       "|      1       |\n",
       "|      1       |\n",
       "+--------------+\n",
       "[152 rows x 5 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd_truthful.filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_truthdict_given_mid_end(mid_date,end_date):\n",
    "#     print(mid_date,end_date, 'mid date end date')\n",
    "    pd_truthful.start_date = mid_date\n",
    "    pd_truthful.end_date = end_date\n",
    "    hd_truthful.start_date = mid_date\n",
    "    hd_truthful.end_date = end_date\n",
    "    truthdict = {\n",
    "    'date':pd_truthful.filtered_data['date'],\n",
    "    'infections':pd_truthful.filtered_data['infections'],\n",
    "    'Rt':pd_truthful.filtered_data['Rt'],\n",
    "    'symptomatic':pd_truthful.filtered_data['symptomatic'],\n",
    "    'severe':pd_truthful.filtered_data['severe'],\n",
    "    'hosp':hd_truthful.filtered_data['previous_day_admission_adult_covid_confirmed'],\n",
    "    }\n",
    "\n",
    "    return truthdict\n",
    "\n",
    "\n",
    "def add_to_dict(d,g):\n",
    "    for k in d.keys():\n",
    "        d[k]=d[k]+g[k]\n",
    "    return d\n",
    "\n",
    "def scale_dict_vals(d,s_txn,s_soj):\n",
    "    for k in d.keys():\n",
    "        if k in ['T_serial','prob_sympt_s','prob_severe_s','prob_hosp_s']:\n",
    "            d[k] = s_txn*d[k]\n",
    "        elif k in ['prob_soujourn_inf_alpha_s', 'prob_soujourn_inf_beta_s', 'prob_soujourn_symp_alpha_s', 'prob_soujourn_symp_beta_s']:\n",
    "            d[k] = s_soj*d[k]\n",
    "        else:\n",
    "            print('UNHANDLED SCALE DICT k=', k)\n",
    "    return d\n",
    "\n",
    "def cumsum_dict_vals(d,s):\n",
    "    cumsum= 0\n",
    "    for k in d.keys():\n",
    "\n",
    "        cumsum+=abs(s*d[k])\n",
    "    return cumsum\n",
    "\n",
    "import numpy as np\n",
    "softplus = lambda x: np.log(1+np.exp(x))\n",
    "softplus_inv = lambda x: np.log(np.exp(x) -1)\n",
    "from scipy.special import expit as sigmoid\n",
    "from scipy.special import logit as sigmoid_inv\n",
    "\n",
    "import numpy.random as random\n",
    "def gradient_descent(pd_list_train, init_params, n_iters=2, step_size_txn=0.001, step_size_soj=0.001, n_steps_between_print=5, lambda_reg = 1, epsilon_stop=5e-10):\n",
    "    grads_per_iteration = {k: [] for k in list(init_params.keys())}\n",
    "    batch_loss_per_iteration = []\n",
    "    val_loss_per_iteration = []\n",
    "    for n in range(n_iters):\n",
    "        \n",
    "        batch_loss = 0\n",
    "        for pd in pd_list_train:\n",
    "            pd.loss_per_iteration += [0]\n",
    "        \n",
    "        #         pd_batch = random.choice(pd_list_train,replace=False, size=3)\n",
    "        pd_batch = random.choice(pd_list_train,replace=False, size=1)\n",
    "        if n == 0:\n",
    "            new_params = init_params\n",
    "        else:\n",
    "            new_params = add_to_dict(new_params, scale_dict_vals(grads, -1*step_size_txn,-1*step_size_soj))\n",
    "        \n",
    "        \n",
    "        for i,pd in enumerate(pd_batch):\n",
    "            pd.training_mode=True\n",
    "            new_grad = pd.get_grad_of_loss(new_params,get_truthdict_given_mid_end(pd.filtered_data['date'][-1], pd.end_date) ,lambda_reg= lambda_reg)\n",
    "            batch_loss += pd.loss_per_iteration[-1] # pd.loss_per_iteration[-1] is set to loss within get_grad_of_loss call\n",
    "            if i == 0:\n",
    "                grads = new_grad\n",
    "            else:\n",
    "#                 grads = add_to_dict(grads, new_grad)\n",
    "                grads = new_grad\n",
    "#         print(grads)\n",
    "        grads = scale_dict_vals(grads, 1/len(pd_batch),1/len(pd_batch))\n",
    "        for k in grads_per_iteration.keys():\n",
    "            grads_per_iteration[k] += [grads[k]]\n",
    "        batch_loss_per_iteration += [batch_loss/len(pd_batch)]\n",
    "#         print(batch_loss/len(pd_batch), 'loss at iteration ', n, '*** gradients_cummsum = ', cumsum_dict_vals(grads, step_size_))\n",
    "        print(batch_loss/len(pd_batch), 'loss at iteration ', n)\n",
    "#         print(cumsum_dict_vals(grads,1), 'cumsum for ', grads)\n",
    "        \n",
    "#         pd_list_val = pd_batch # DEBUG PURPOSES\n",
    "        \n",
    "        val_loss_per_iteration += [np.nan]\n",
    "        if n%n_steps_between_print == 0:\n",
    "            val_loss = 0              \n",
    "            for pd in pd_list_val:\n",
    "                fig, [ax1, ax2, ax3, ax4] = plt.subplots(nrows=1, ncols=4,figsize=(15,4))    \n",
    "                pd.training_mode=False\n",
    "                fc_data = pd.get_forecasted_data(new_params) \n",
    "                pd.training_mode=True\n",
    "                truth_data = get_truthdict_given_mid_end(pd.filtered_data['date'][-1],pd.end_date)\n",
    "#                 print('***grads***','\\n',grads,'\\n')\n",
    "                ax1.plot(fc_data['infections'])\n",
    "                ax2.plot(fc_data['symptomatic'])\n",
    "                ax3.plot(fc_data['severe'])\n",
    "                ax4.plot(fc_data['hosp'])\n",
    "\n",
    "                ax1.plot(truth_data['infections'])\n",
    "                ax2.plot(truth_data['symptomatic'])\n",
    "                ax3.plot(truth_data['severe'])\n",
    "                ax4.plot(truth_data['hosp'])\n",
    "                for i in range(1,5,1):\n",
    "                    eval('ax' + str(i) + '.grid()') \n",
    "                plt.show()\n",
    "                print('new_params = ',new_params,'\\n')\n",
    "                loss = 0\n",
    "                for i,k in enumerate(['hosp']):\n",
    "                    val_loss+=np.sum(np.abs(np.array(fc_data[k]) - np.array(truth_data[k]))*np.linspace(0.1, 1, num=len(fc_data[k])) )*(i+1)\n",
    "            val_loss_per_iteration[-1] = val_loss/len(pd_list_val)\n",
    "        \n",
    "#         if cumsum_dict_vals(grads, step_size)<epsilon_stop:\n",
    "#             return new_params, batch_loss_per_iteration, val_loss_per_iteration\n",
    "    return new_params, batch_loss_per_iteration, val_loss_per_iteration,grads_per_iteration\n",
    "\n",
    "# train_params = {'T_serial':5.8,'prob_sympt':0.82,'prob_severe':0.2,'prob_hosp':0.25,'prob_soujourn_inf_alpha':3.41, 'prob_soujourn_inf_beta':0.605,'prob_soujourn_symp_alpha':1.62, 'prob_soujourn_symp_beta':0.218}\n",
    "##TODO REPARAM change the relevant params to be their inverse fn transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd_list_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-78f21a7b095c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     'prob_soujourn_symp_alpha_s':softplus_inv(1.62), 'prob_soujourn_symp_beta_s':softplus_inv(0.218)}\n\u001b[1;32m      5\u001b[0m     new_params, batch_loss_per_iteration, val_loss_per_iteration,grads_per_iteration = gradient_descent(\n\u001b[0;32m----> 6\u001b[0;31m         pd_list_train, train_params, n_iters=11, step_size_txn=5e-6, step_size_soj=9e-5, n_steps_between_print=5, lambda_reg=1e-3,epsilon_stop=1e-4)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd_list_train' is not defined"
     ]
    }
   ],
   "source": [
    "if not RELOADING_RESULTS:\n",
    "    train_params = {'T_serial':5.8,'prob_sympt_s':sigmoid_inv(0.82),'prob_severe_s':sigmoid_inv(0.2),'prob_hosp_s':sigmoid_inv(0.25),\n",
    "                    'prob_soujourn_inf_alpha_s':softplus_inv(3.41), 'prob_soujourn_inf_beta_s':softplus_inv(0.605),\n",
    "                    'prob_soujourn_symp_alpha_s':softplus_inv(1.62), 'prob_soujourn_symp_beta_s':softplus_inv(0.218)}\n",
    "    new_params, batch_loss_per_iteration, val_loss_per_iteration,grads_per_iteration = gradient_descent(\n",
    "        pd_list_train, train_params, n_iters=11, step_size_txn=5e-6, step_size_soj=9e-5, n_steps_between_print=5, lambda_reg=1e-3,epsilon_stop=1e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "for k in grads_per_iteration:\n",
    "    if k in ['T_serial', 'prob_sympt_s', 'prob_severe_s', 'prob_hosp_s']:\n",
    "        plt.plot((grads_per_iteration[k][1:]), label=k, linestyle=':')\n",
    "    else:\n",
    "        plt.plot((grads_per_iteration[k][1:]), label=k, linestyle='-')\n",
    "plt.legend()\n",
    "plt.xlabel('iteration #')\n",
    "plt.ylabel('gradients of reparameterized parameters')\n",
    "plt.title('full 50 iterations')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "for k in grads_per_iteration:\n",
    "    if k in ['T_serial', 'prob_sympt_s', 'prob_severe_s', 'prob_hosp_s']:\n",
    "        plt.plot((grads_per_iteration[k][30:]), label=k, linestyle=':')\n",
    "    else:\n",
    "        plt.plot((grads_per_iteration[k][30:]), label=k, linestyle='-')\n",
    "plt.legend()\n",
    "plt.xlabel('iteration #')\n",
    "plt.ylabel('gradients of reparameterized parameters')\n",
    "# plt.yscale('log')\n",
    "plt.title('last 20 iterations shown for better y-scale interpretation')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.rcParams.update({'font.size': 20})\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "plt.plot(batch_loss_per_iteration,color='r', label='batched_training_loss')\n",
    "# plt.show()\n",
    "\n",
    "plt.scatter(list(range(len(val_loss_per_iteration))),val_loss_per_iteration,label='validation_loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "plt.plot(batch_loss_per_iteration,color='r', label='batched_training_loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('iteration number')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "plt.scatter(list(range(len(val_loss_per_iteration))),val_loss_per_iteration,label='validation_loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('iteration number')\n",
    "plt.show()\n",
    "\n",
    "# print(val_loss_per_iteration)\n",
    "# import numpy as np\n",
    "# np.linspace(1, 10, num=10) * np.array(np.linspace(0.1, 1, num=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def roundup100th(x):\n",
    "    if x<=200:\n",
    "        return int(math.ceil(x / 25.0)) * 25\n",
    "    else:\n",
    "        return int(math.ceil(x / 100.0)) * 100\n",
    "\n",
    "def plot_performance(new_params):\n",
    "    color_list = ['k','k','k','k','k']\n",
    "    fig, [ax1, ax2, ax3, ax4, ax5] = plt.subplots(nrows=5, ncols=1,figsize=(15,15), sharex=True)   \n",
    "    truth_data = get_truthdict_given_mid_end('20210101', '20210601')\n",
    "    print(pd_truthful.start_date, ' to ', pd_truthful.end_date)\n",
    "    print('cyan = forecasts after being trained on that interval')\n",
    "    print('violet = forecasts on validation/unseen interval')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    for i,(p,c) in enumerate(zip(['Rt','infections', 'symptomatic', 'severe','hosp'],color_list)):\n",
    "        if p != 'Rt':\n",
    "            eval('ax'+str(i+1) + \".plot( truth_data[p], color = c,ls=':' )\")\n",
    "        if p == 'Rt':\n",
    "            eval('ax'+str(i+1) + \".plot( truth_data[p], color = 'g',ls=':' )\")\n",
    "        \n",
    "        if p != 'Rt':\n",
    "            eval('ax'+str(i+1) + \".plot( truth_data[p], color = c,ls=':' )\")\n",
    "                            \n",
    "        for pd in pd_list_train:\n",
    "            pd.training_mode = False\n",
    "            fc_data = pd.get_forecasted_data(new_params) \n",
    "            print(pd.start_date, pd.end_date, 'start and end date')\n",
    "#             print(pd.start_date,pd.end_date,'start end date')\n",
    "#             print(truth_data,'truth data')\n",
    "#             print(fc_data[-10:],'fc_data data')\n",
    "#             return\n",
    "    #         '-', '--', '-.', ':',\n",
    "            start_idx = list(truth_data['date']).index(int(fc_data['date'][0]))\n",
    "            end_idx = start_idx + len(fc_data['date']) - 1\n",
    "            if p != 'Rt':\n",
    "                eval('ax'+str(i+1) + \".plot( list(range(start_idx,end_idx+1)),fc_data[p], color = 'c',ls = '-' )\")\n",
    "            else:\n",
    "                eval('ax'+str(i+1) + \".plot( list(range(start_idx,end_idx+1)),fc_data[p], color = 'k',ls = ':' )\")\n",
    "\n",
    "        #         for pd in pd_list_val:\n",
    "#         for pd in pd_list_train:\n",
    "#             pd.training_mode = False\n",
    "#             end_date_original = pd.end_date\n",
    "#             pd.end_date = str((datetime.datetime.strptime(str(end_date_original),'%Y%m%d') + datetime.timedelta(days = forecast_duration)).strftime('%Y%m%d'))\n",
    "#             fc_data = pd.get_forecasted_data(new_params) \n",
    "#     #         '-', '--', '-.', ':',\n",
    "#             start_idx = list(truth_data['date']).index(int(fc_data['date'][0]))\n",
    "#             end_idx = start_idx + len(fc_data['date']) - 1\n",
    "#             if p != 'Rt':\n",
    "#                 eval('ax'+str(i+1) + \".plot( list(range(start_idx,end_idx+1)),fc_data[p], color = 'm',ls = ':' )\")\n",
    "#             else:\n",
    "#                 eval('ax'+str(i+1) + \".plot( list(range(start_idx,end_idx+1)),fc_data[p], color = 'k',ls = ':' )\")\n",
    "            \n",
    "#             pd.end_date = end_date_original\n",
    "#         eval('ax'+str(i+1) + '.set_title(p)')\n",
    "#         eval('ax'+str(i+1) + '.grid()')\n",
    "#     # current_labels = ax4.get_xticklabels()\n",
    "\n",
    "    #     eval('ax'+str(i+1) + \".set_xticklabels( [str(d) for d in list(truth_data['date']) ] )\" )\n",
    "    current_labels = ax4.get_xticks();\n",
    "    date_labels = [truth_data['date'][int(jj)] if jj<len(truth_data['date']) else '' for jj in list(current_labels[1:-1]) ]\n",
    "\n",
    "    ax4.set_xticklabels(['']+ date_labels)\n",
    "    \n",
    "    maxy = max(int(np.max(np.array(truth_data['hosp']))),int(np.max(np.array(fc_data['hosp']))))\n",
    "    ax5.set_yticks(np.arange(0, maxy, step=roundup100th(maxy/6)))\n",
    "    ax5.figure.savefig(results_folder+state_short+'_hosp_forecast_trained_on_'+str(training_mid_dates[0])+'_'+str(training_end_dates[0])  +'.pdf', bbox_inches='tight')\n",
    "# train_params = {'T_serial':5.8,'prob_sympt':0.536,'prob_severe':0.1,'prob_hosp':0.55,'prob_soujourn_inf_alpha':3.41, 'prob_soujourn_inf_beta':0.605,'prob_soujourn_symp_alpha':1.62, 'prob_soujourn_symp_beta':0.218}\n",
    "# train_params = {'T_serial':5.8,'prob_sympt':0.82,'prob_severe':0.2,'prob_hosp':0.25,'prob_soujourn_inf_alpha':3.41, 'prob_soujourn_inf_beta':0.605,'prob_soujourn_symp_alpha':1.62, 'prob_soujourn_symp_beta':0.218}\n",
    "\n",
    "\n",
    "train_params = {'T_serial':5.8,'prob_sympt_s':sigmoid_inv(0.82),'prob_severe_s':sigmoid_inv(0.2),'prob_hosp_s':sigmoid_inv(0.25),\n",
    "                'prob_soujourn_inf_alpha_s':softplus_inv(3.41), 'prob_soujourn_inf_beta_s':softplus_inv(0.605),\n",
    "                'prob_soujourn_symp_alpha_s':softplus_inv(1.62), 'prob_soujourn_symp_beta_s':softplus_inv(0.218)}\n",
    "\n",
    "print(train_params)\n",
    "plot_performance(train_params)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "####PICKLE RELOAD NEW PARAMS IN \n",
    "if RELOADING_RESULTS:\n",
    "    import pickle\n",
    "    filename = results_folder+ state_short + '_population_params_trained_on_'+str(training_mid_dates[0])+'_'+str(training_end_dates[0])\n",
    "\n",
    "    with open(filename+'.pickle', 'rb') as handle:\n",
    "        new_params = pickle.load(handle)\n",
    "\n",
    "\n",
    "print(new_params)\n",
    "plot_performance(new_params)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_list_train[0].end_date = '20210501'\n",
    "pd_list_train[0].end_date = '20210801'\n",
    "pd_list_train[0].get_forecasted_data(new_params, save_admissions=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not RELOADING_RESULTS: # save newly learned results\n",
    "    import pickle\n",
    "    filename = results_folder+state_short + '_population_params_trained_on_'+str(training_mid_dates[0])+'_'+str(training_end_dates[0])\n",
    "    with open(filename+'.pickle', 'wb') as handle:\n",
    "        pickle.dump(new_params, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open(filename+'.pickle', 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "\n",
    "    print (new_params == b)\n",
    "    print(new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO consider plotting the prior distrobutions and consider plotting posterior distribution\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "prior_params_ab = {'prob_sympt_s':[5.5,2],'prob_severe_s':[2,5],'prob_hosp_s':[2,4]}\n",
    "\n",
    "        \n",
    "for k,v in prior_params_ab.items():\n",
    "    a = v[0]\n",
    "    b = v[1]\n",
    "    mean, var, skew, kurt = beta.stats(a, b, moments='mvsk')\n",
    "#     print(mean,'*mean value given a,b*', a,b)\n",
    "#     print(var,'*var value given a,b*', a,b)\n",
    "    print(sigmoid(new_params[k]), 'optimized param', k)\n",
    "\n",
    "    x = np.linspace(0,1,1000)\n",
    "    pdf_vals = beta.pdf(x, a, b)\n",
    "    imax = np.argmax(pdf_vals)\n",
    "    print(x[imax],'*mode value given a,b*', a,b)\n",
    "    plt.plot(x, pdf_vals,\n",
    "           'k-', lw=5, label=k+' beta prior')\n",
    "#     plt.vlines(sigmoid(new_params[k]),np.min(pdf_vals),beta.pdf(sigmoid(new_params[k]), a, b), label='optimized '+ k)\n",
    "\n",
    "#     plt.legend(loc='best', frameon=False)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.savefig(results_folder+state_short+'_prior_'+ k+'_'+str(training_mid_dates[0])+'_'+str(training_end_dates[0])  +'.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import gamma\n",
    "# import matplotlib.pyplot as plt\n",
    "import math\n",
    "qfn = lambda a,b,c: [(-b + math.sqrt(b**2 - (4*a*c) )) / (2 * a),(-b - math.sqrt(b**2 - (4*a*c) )) / (2 * a)]\n",
    "\n",
    "            # self.params['prob_soujourn_inf_alpha']= 3.41\n",
    "    # self.params['prob_soujourn_inf_beta']= 0.605\n",
    "    # self.params['prob_soujourn_symp_alpha']= 1.62\n",
    "    # self.params['prob_soujourn_symp_beta']= 0.218\n",
    "soj_new_params = [softplus(new_params['prob_soujourn_inf_alpha_s']),softplus(new_params['prob_soujourn_inf_beta_s']),\n",
    "                  softplus(new_params['prob_soujourn_symp_alpha_s']),softplus(new_params['prob_soujourn_symp_beta_s'])\n",
    "                 ]\n",
    "soj_param_names = ['prob_soujourn_inf_alpha_s','prob_soujourn_inf_beta_s','prob_soujourn_symp_alpha_s','prob_soujourn_symp_beta_s']\n",
    "for i,mode_value in enumerate([3.41,0.605,1.62,0.218]):\n",
    "# for i,mode_value in enumerate([3.41,0.605,1.62,0.23]):\n",
    "    betas = qfn(4,-mode_value,-1)\n",
    "    beta = max(betas)\n",
    "\n",
    "    a = 4*beta**2\n",
    "\n",
    "    print(a,beta, 'a,b')\n",
    "    print(soj_new_params[i], '= optimized', soj_param_names[i])\n",
    "\n",
    "#     fig, ax = plt.subplots(1, 1)\n",
    "    x = np.linspace(0,15, 1000)\n",
    "    rv = gamma(a,scale=1/beta)\n",
    "    pdf_vals = rv.pdf(x)\n",
    "    imax = np.argmax(pdf_vals)\n",
    "    \n",
    "    plt.plot(x, pdf_vals, 'k-', lw=5, label='gamma prior')\n",
    "    print('mode value = ' + str(x[imax]) + ' vs opt ' + str(soj_new_params[i]))\n",
    "#     plt.vlines(soj_new_params[i], ymin=0,ymax=rv.pdf(soj_new_params[i]),label='optimized param')\n",
    "\n",
    "#     plt.legend(loc='best', frameon=False)\n",
    "#     plt.title('mode value = ' + str(mode_value) + ' vs opt ' + str(soj_new_params[i]))\n",
    "    plt.grid()\n",
    "    plt.savefig(results_folder+state_short+'_prior_'+ soj_param_names[i]+'_'+str(training_mid_dates[0])+'_'+str(training_end_dates[0])  +'.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from scipy.special import gamma as gamma_fcn\n",
    "from autograd_gamma import gammainc\n",
    "\n",
    "from scipy.special import expit as sigmoid\n",
    "from scipy.special import logit as sigmoid_inv\n",
    "softplus = lambda x: np.log(1+np.exp(x))\n",
    "\n",
    "softplus_inv = lambda x: np.log(np.exp(x) -1)\n",
    "def log_gamma_pdf(x,alpha,beta):\n",
    "    return alpha*np.log(beta) + (alpha-1)*np.log(x) - (beta*x) - np.log(gamma_fcn(alpha))\n",
    "\n",
    "def gamma_at_x(params,x):\n",
    "    if x==0:\n",
    "        return 0.0 \n",
    "    if x==1:\n",
    "        return cdf_at_x(params,x)\n",
    "    elif x>1:\n",
    "        return cdf_at_x(params,x) - cdf_at_x(params,x-1)\n",
    "\n",
    "def cdf_at_x(params,x):\n",
    "    return (gammainc(params['alpha'],params['beta']*x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # self.params['prob_soujourn_inf_alpha']= 3.41\n",
    "    # self.params['prob_soujourn_inf_beta']= 0.605\n",
    "    # self.params['prob_soujourn_symp_alpha']= 1.62\n",
    "    # self.params['prob_soujourn_symp_beta']= 0.218\n",
    "from matplotlib.pyplot import stem\n",
    "########## INF SOJOURN\n",
    "a = softplus(new_params['prob_soujourn_inf_alpha_s'])\n",
    "beta = softplus(new_params['prob_soujourn_inf_beta_s'])\n",
    "x = np.linspace(1,40, 40)\n",
    "rv = gamma(a,scale=1/beta)\n",
    "rv0 = gamma(3.41,scale=1/.605)\n",
    "\n",
    "# plt.plot(x, rv.pdf(x), 'r-', lw=5, label='inf soj posterior')\n",
    "# plt.plot(x, rv0.pdf(x), 'k-', lw=5, label='inf soj prior pdf')\n",
    "\n",
    "stem(x, [gamma_at_x({'alpha':3.41,'beta':.605},val) for val in x], linefmt='k-', markerfmt='ks', basefmt='r-', label='prior PMF')\n",
    "stem(x, [gamma_at_x({'alpha':a,'beta':beta},val) for val in x], linefmt='b:', markerfmt='bo', basefmt='r-', label='MAP PMF')\n",
    "# plt.bar(x,[gamma_at_x({'alpha':a,'beta':beta},val) for val in x])\n",
    "# plt.vlines(soj_new_params[i], ymin=0,ymax=rv.pdf(soj_new_params[i]),label='optimized param')\n",
    "plt.title('I-Sojourn-PMF')\n",
    "plt.legend(loc='best', frameon=False)\n",
    "# plt.title('mode value = ' + str(mode_value) + ' vs opt ' + str(soj_new_params[i]))\n",
    "plt.grid()\n",
    "plt.savefig(results_folder+state_short+'_MAP_'+ '_I-Sojourn-PMF_'+'_'+str(training_mid_dates[0])+'_'+str(training_end_dates[0])  +'.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "        \n",
    "        \n",
    "########## SYMP SOJOURN\n",
    "                  \n",
    "                  \n",
    "a = softplus(new_params['prob_soujourn_symp_alpha_s'])\n",
    "beta = softplus(new_params['prob_soujourn_symp_beta_s'])\n",
    "\n",
    "x = np.linspace(1,40, 40)\n",
    "rv = gamma(a,scale=1/beta)\n",
    "rv0 = gamma(1.62,scale=1/.218)\n",
    "\n",
    "# plt.plot(x, rv.pdf(x), 'r-', lw=5, alpha=0.6, label='symp soj posterior')\n",
    "# plt.plot(x, rv0.pdf(x), 'k:', lw=3, label='symp soj prior')\n",
    "# plt.vlines(soj_new_params[i], ymin=0,ymax=rv.pdf(soj_new_params[i]),label='optimized param')\n",
    "stem(x, [gamma_at_x({'alpha':1.62,'beta':.218},val) for val in x], linefmt='k-', markerfmt='ks', basefmt='r-', label='prior PMF')\n",
    "stem(x, [gamma_at_x({'alpha':a,'beta':beta},val) for val in x], linefmt='b:', markerfmt='bo', basefmt='r-', label='MAP PMF')\n",
    "plt.title('S-Sojourn-PMF')\n",
    "\n",
    "plt.legend(loc='best', frameon=False)\n",
    "# plt.title('mode value = ' + str(mode_value) + ' vs opt ' + str(soj_new_params[i]))\n",
    "plt.grid()\n",
    "plt.savefig(results_folder+state_short+'_MAP_'+ '_S-Sojourn-PMF_'+'_'+str(training_mid_dates[0])+'_'+str(training_end_dates[0])  +'.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "softplus(200e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
