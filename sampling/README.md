# ABC MCMC to estimate parameters of hospital model
Gian Marco Visani - 03/28/2021

Implements ABC MCMC drawn from https://arxiv.org/pdf/1001.2058.pdf, with some variations.  
Preprint describing the full procedureas well as the use cases of the model coming soon!

## Setup

Requirements:  
- A json file containing the prior over each set of parameters  
- A json file containing the config information necessary for the hospital model to run a simulation. This includes:  
    - Initial counts at each state of the hospital  
    - Number of timesteps to simulate (training + testing)  
    - Number of *training* timesteps only  
    - A source to draw admissions from, usually a pointer to a file containing admissions per timestep  
    - Parameters of the model. Values are just placeholders, with the exception of *proba_Die_after_Declining_OnVentInICU* which must be set to 1.0 and never changed  
- A csv file containing admissions per timestep. These admissions an be at any state of the hospital  
- A csv file containing the true hospital census counts for training and testing

## US States data collection

We provide code and a notebook to automatically collect and format US state level data from HHS and from the Covid Tracking project.  
The code snippet (latest version) is USA/HospitalData_v20210330.py and the notebook is USA/generate_US_states_data.ipynb.  
Currently, the smoothing of terminal counts is not automatically generated.

## Step 0: Setup the use of cython (if C programming language is installed)

We provide a cython implementation of our model, which grants a 2-fold speedup over our optimized python implementation.  
To setup the use of cython, run the following command:  
    `python setup.py build_ext --inplace`  
Then, to use the cython implementation, set the argument *func_name* to *cython* in any script that has the argument.

## Step 1: Run ABC

Run the following command:  
    `python sampling_fast_code_clean.py`

See the file for an explanation of the arguments.

Output:  
- Samples file (json), containing the last 2000 samples of parameters as a list of dictionaries  
- Stats file (csv) containing a history of all relevant statistics at each step of the sampling procedure (epsilon trace, accepted distances, all distances, accepted alphas, all alphas). Useful to check convergence of the algorithm (code to automatically analyze this coming soon).
<!--     - The last 1000 forecasts on testing (in a single, easy to parse csv file), each generated by the last 1000 sampled sets of parameters. These forecasts are generated together with the training data, and thus they are'warmed-up', i.e. the patients present in the hospital at day zero of testing are assumed to have been there for some realistic nnumber of days already -->

<!-- ## Step 2: unpack warmed-up forecasts on testing into individual csv files

Run the following command:
    `python collect_warmed_up_forecasts.py --concat_file [results/abc_MA_last_forecasts.csv] --num_samples 100 --output_file [results_MA_index=0.csv]`

Note: must include '\_index=0' at the end of your desired filename to allow the scripts to generate and then identify the individual forecasts.

This step is only performed to make the input compatible with files summarize_forecasts.py and ABC_test_metrics.py. Alternatively, those two files can be changed to take as input the unpacked forecasts. -->

## Step 2: run forecasts (training + testing)

Run the following command:  
    `python run_forecast_from_samples_fast.py --func_name [python] --params_json_file [USA/MA_data/config_MA_NovToFeb_61days.json]
                                              --samples_file [USA/MA_results/abc_MA_NovToFeb_61days_last_thetas_OnCDCTableReasonable.json]
                                              --output_file [USA/MA_output/results_MA_NovToFeb_61days_OnCDCTableReasonable_random_seed=1001.csv]
                                              --approximate [7] --random_seed [1001] --num_seeds [500]`

Arguments:  
- *params_json_file* is the config file for the model.  
- *approximate* number of patients modeled jointly. Higher approximation means less granularity in forecast, but much higher speedup. We recommend the use of higher approximations for higher admissions regimes, where the speedup is much needed and the granularity can be lower without reducing the quality of the forecasts.  
- *samples_file* contains the parameters used for forecasting. Must be in the same format as the output of `sampling_fast_code_clen.py`. **One** set of parameters is used for **one** forecast with a unique random seed.  
- *output_file*: must include '\_random_seed=SEED' at the end of your desired output file to allow the scripts to generate and then identify the individual forecasts, where SEED must match the value passed to the argument *random_seed*. The script will generate *num_seeds* csv files, each containing one forecast.  

We already provide a set of samples from the posterior distribution trained on Massachusetts from Nov 11th to Jan 11th. To make the forecasts, simply set *samples_file* to 'USA/MA_results/MA_NovToFeb_61days_OnCDCTableReasonable_samples.json'.

We **strongly** recommend making forecasts using samples from multiple runs of ABC, as opposed to just one.

## Step 3: compute summaries of forecasts

Run the following command:  
    `python summarize_forecasts.py --input_dir [USA/MA_output] --output_dir [USA/MA_output] 
                                   --output_template [summary_MA_NovToFeb_61days_OnCDCTableReasonable_]
                                   --input_csv_file_pattern [results_MA_NovToFeb_61days_OnCDCTableReasonable_random_seed*.csv] 
                                   --comma_sep_percentiles [1,2.5,5,10,25,50,75,90,95,97.5,99] --include_los [False]`

Arguments:  
- *input_csv_file_pattern* identifies all the files containing the forecasts from the script collect_warmed_up_forecasts.py.  
- *include_los* says whether we want to compute summaries for the los results as well currently unused, do not set to True).

The summaries include (one file for each one): mean, stddev, and all percentiles specified by *comma_sep_percentiles*.

## Step 4: compute relevant metrics

Run the following command:  
    `python ABC_test_metrics.py --input_dir [USA/MA_output] --output_dir [USA/MA_results] --output_template [metrics_MA_NovToFeb_61days_OnCDCTableReasonable] 
                                --true_stats [USA/MA_data/MA_NovToFeb_61days.csv]
                                --input_summaries_template [summary_MA_NovToFeb_61days_OnCDCTableReasonable_] --coverages [2.5_97.5,10_90,25_75]
                                --comma_sep_expected_columns [n_InGeneralWard,n_OffVentInICU,n_OnVentInICU,n_TERMINAL,n_TERMINAL_5daysSmoothed]`

Arguments:  
- *input_summaries_template* identifies the files containing summaries of the forecasts, i.e. the files generated by the script summarize_forecasts.py.

The script currently computes:  
- MAE for each expected_column, averaged over timesteps.  
- Coverage for each expected_column. Coverages are user-specified in the following format: low1_high1,low2_high2,...,lowN_highN. The requested coverages must be computable from the percentiles computed in step 3 (e.g. can compute 10\_90 coverage only if 10 and 90 percentiles were computed in step 3).
