Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 2
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job counts:
	count	jobs
	1	template
	1

[Mon Apr  6 22:31:44 2020]
rule template:
    input: params.json, /cluster/tufts/hugheslab/code/covid19-forecasting/run_forecast.py, /cluster/tufts/hugheslab/code/covid19-forecasting/semimarkov_forecaster/__init__.py, /cluster/tufts/hugheslab/code/covid19-forecasting/semimarkov_forecaster/PatientTrajectory.py
    output: /cluster/tufts/hugheslab/mhughe02/forecast_results/demo_20200406/results-random_seed=101.csv
    jobid: 0
    wildcards: output_dir=/cluster/tufts/hugheslab/mhughe02/forecast_results/demo_20200406, random_seed=101

        dirname /cluster/tufts/hugheslab/mhughe02/forecast_results/demo_20200406/results-random_seed=101.csv | xargs mkdir -p &&         python /cluster/tufts/hugheslab/code/covid19-forecasting/run_forecast.py             --config_file "params.json"             --random_seed "101"             --output_file "/cluster/tufts/hugheslab/mhughe02/forecast_results/demo_20200406/results-random_seed=101.csv"         
Traceback (most recent call last):
  File "/cluster/tufts/hugheslab/code/covid19-forecasting/run_forecast.py", line 23, in <module>
    config_dict = json.load(f)
  File "/cluster/tufts/hugheslab/miniconda2/envs/semimarkov_forecaster/lib/python3.8/json/__init__.py", line 293, in load
    return loads(fp.read(),
  File "/cluster/tufts/hugheslab/miniconda2/envs/semimarkov_forecaster/lib/python3.8/json/__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "/cluster/tufts/hugheslab/miniconda2/envs/semimarkov_forecaster/lib/python3.8/json/decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 11 (char 10)
[Mon Apr  6 22:31:52 2020]
Error in rule template:
    jobid: 0
    output: /cluster/tufts/hugheslab/mhughe02/forecast_results/demo_20200406/results-random_seed=101.csv
    shell:
                dirname /cluster/tufts/hugheslab/mhughe02/forecast_results/demo_20200406/results-random_seed=101.csv | xargs mkdir -p &&         python /cluster/tufts/hugheslab/code/covid19-forecasting/run_forecast.py             --config_file "params.json"             --random_seed "101"             --output_file "/cluster/tufts/hugheslab/mhughe02/forecast_results/demo_20200406/results-random_seed=101.csv"         
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
