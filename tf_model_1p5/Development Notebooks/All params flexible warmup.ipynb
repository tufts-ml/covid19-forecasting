{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "969ad8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-02 14:10:57.220646: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-02 14:10:57.220700: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "sys.path.append('/mnt/c/Users/kheut/code/covid19-forecasting/tf_model_1p5/')\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "from scipy.stats import beta, truncnorm\n",
    "\n",
    "\n",
    "# Local imports from model.py, data.py\n",
    "from model import CovidModel, LogPoissonProb, get_logging_callbacks, Comp, Vax\n",
    "from data import read_data, create_warmup\n",
    "#from plots import make_all_plots\n",
    "\n",
    "import scipy\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 20}) # set plot font sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffdbf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_window =10\n",
    "\n",
    "warmup_start = '20210421'\n",
    "warmup_end = '20210430'\n",
    "train_start = '20210501'\n",
    "train_end = '20210731'\n",
    "test_start = '20210801'\n",
    "test_end = '20210831'\n",
    "\n",
    "state = 'Massachusetts'\n",
    "state_abbrev = 'MA'\n",
    "\n",
    "data_dir = '../data'\n",
    "covid_estim_date = '20210901'\n",
    "hhs_date = '20210903'\n",
    "owid_date = '20210903'\n",
    "\n",
    "# Learning rate\n",
    "model_learning_rate = 1e-2\n",
    "warmup_learning_rate = 20\n",
    "learning_rate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8af6455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data(data_dir=data_dir,\n",
    "               covid_estim_date=covid_estim_date,\n",
    "               hhs_date=hhs_date,\n",
    "               owid_date=owid_date,\n",
    "               state=state, state_abbrev=state_abbrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0edb57a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comp(Enum):\n",
    "    A = 0\n",
    "    M = 1\n",
    "    #X = 2\n",
    "    #G = 3\n",
    "    \n",
    "class Vax(Enum):\n",
    "    total = -1\n",
    "    no = 0\n",
    "    yes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3220d0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get warmup arrays, splitting on vaccination status\n",
    "warmup_asymp, warmup_mild, warmup_extreme = create_warmup(df, \n",
    "                                                          warmup_start, \n",
    "                                                          warmup_end,\n",
    "                                                          0,0,0)\n",
    "\n",
    "# re-combine\n",
    "warmup_asymp = warmup_asymp[Vax.no.value] + warmup_asymp[Vax.yes.value]\n",
    "warmup_mild = warmup_mild[Vax.no.value] + warmup_asymp[Vax.yes.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "086cb3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_T_serial = 5.8\n",
    "synth_rho_M = 0.76\n",
    "synth_lambda_M = 4.7\n",
    "synth_nu_M = 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddd9c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_A_params = {}\n",
    "warmup_A_params[Vax.total.value] = {}\n",
    "warmup_A_params[Vax.total.value]['prior'] = []\n",
    "warmup_A_params[Vax.total.value]['posterior_init'] = []\n",
    "\n",
    "for day in range(transition_window):\n",
    "    warmup_A_params[Vax.total.value]['prior'].append({'loc': warmup_asymp[day],\n",
    "                                                'scale': warmup_asymp[day]/10})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3dd3b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-02 14:11:35.222408: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-02 14:11:35.222473: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-02 14:11:35.222498: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-ODFHK4CF): /proc/driver/nvidia/version does not exist\n",
      "2022-01-02 14:11:35.222878: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.cast(df.loc[train_start:test_end,'Rt'].values, dtype=tf.float32)\n",
    "y_test = tf.cast(df.loc[train_start:test_end,'mild'], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b36af2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_vals = []\n",
    "M_vals =[]\n",
    "for day in range(transition_window):\n",
    "    A_vals.append(warmup_A_params[-1]['prior'][day]['loc'])\n",
    "\n",
    "for day in range(len(x_train)):\n",
    "    yesterday_asymp = A_vals[-1]\n",
    "    \n",
    "    today_asymp = yesterday_asymp*x_train[day]**(1/synth_T_serial)\n",
    "    A_vals.append(today_asymp)\n",
    "    \n",
    "    today_M = 0\n",
    "    pi_M=[]\n",
    "    for j in range(transition_window):\n",
    "        \n",
    "        \n",
    "        lambda_M_fix = synth_lambda_M\n",
    "        nu_M_fix = synth_nu_M\n",
    "        poisson_dist = scipy.stats.poisson(lambda_M_fix)\n",
    "        pi_M_j_ago = poisson_dist.logpmf(j+1)/nu_M_fix\n",
    "        \n",
    "        pi_M.append(pi_M_j_ago)\n",
    "    \n",
    "    pi_M = scipy.special.softmax(pi_M)\n",
    "        \n",
    "    for j in range(transition_window):\n",
    "        j_ago_asymp = A_vals[day-j-1]\n",
    "        today_M += j_ago_asymp*synth_rho_M*pi_M[j]\n",
    "        \n",
    "    M_vals.append(today_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8c90605",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "T_serial = {}\n",
    "T_serial[Vax.total.value] = {}\n",
    "T_serial[Vax.total.value]['prior'] ={'loc':5.8, 'scale':1}\n",
    "\n",
    "\n",
    "rho_M = {}\n",
    "rho_M[Vax.total.value] = {}\n",
    "rho_M[Vax.total.value]['prior'] = {'a': 31.8, 'b': 10.3}\n",
    "\n",
    "lambda_M = {}\n",
    "lambda_M[Vax.total.value] = {}\n",
    "lambda_M[Vax.total.value]['prior'] = {'loc': 4.7, 'scale': 1}\n",
    "\n",
    "nu_M = {}\n",
    "nu_M[Vax.total.value] = {}\n",
    "nu_M[Vax.total.value]['prior'] = {'loc': 3.1, 'scale': 1.2}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1829678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_serial_scale = 1.0\n",
    "rho_M_scale = 0.1\n",
    "lambda_M_scale = 1.0\n",
    "nu_M_scale = 1.2\n",
    "\n",
    "warmup_scales = [0.1]*warmup_asymp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a56b9dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
     ]
    }
   ],
   "source": [
    "T_serial[Vax.total.value]['posterior_init'] = {'loc': tfp.math.softplus_inverse(4.0),\n",
    "                                     'scale':tf.cast(tfp.math.softplus_inverse(T_serial_scale),dtype=tf.float32)}\n",
    "\n",
    "rho_M[Vax.total.value]['posterior_init'] = {'loc': tf.cast(np.log(0.5/(1-0.5)),dtype=tf.float32),\n",
    "                                      'scale':tf.cast(tfp.math.softplus_inverse(rho_M_scale),dtype=tf.float32)}\n",
    "\n",
    "lambda_M[Vax.total.value]['posterior_init'] = {'loc': tf.cast(tfp.math.softplus_inverse(3.0),dtype=tf.float32),\n",
    "                                         'scale':tf.cast(tfp.math.softplus_inverse(lambda_M_scale),dtype=tf.float32)}\n",
    "\n",
    "nu_M[Vax.total.value]['posterior_init'] = {'loc': tf.cast(tfp.math.softplus_inverse(5.0),dtype=tf.float32),\n",
    "                                     'scale':tf.cast(tfp.math.softplus_inverse(nu_M_scale),dtype=tf.float32)}\n",
    "\n",
    "for day in range(transition_window):\n",
    "    # must be positive so reverse softplus the mean\n",
    "    warmup_A_params[Vax.total.value]['posterior_init'].append({'loc': tf.cast(tfp.math.softplus_inverse(2000.0),dtype=tf.float32),\n",
    "                                                         'scale': tf.cast(tfp.math.softplus_inverse(500.0),dtype=tf.float32)})#tf.cast(tfp.math.softplus_inverse(warmup_asymp[day]/10),dtype=tf.float32)})\n",
    "\n",
    "model = CovidModel([Vax.total], [Comp.A, Comp.M],\n",
    "                 transition_window,\n",
    "                T_serial, rho_M, lambda_M, nu_M,\n",
    "                 warmup_A_params, posterior_samples=1000, debug_disable_theta=False)\n",
    "\n",
    "pre_training_preds=tf.reduce_mean(model.call(x_train), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09ed1fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-02 14:11:53.547396: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'T_serial_A_loc_-1:0' shape=() dtype=float32, numpy=3.9815147>,\n",
       " <tf.Variable 'T_serial_A_scale_-1:0' shape=() dtype=float32, numpy=0.54132485>,\n",
       " <tf.Variable 'rho_M_loc_-1:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'rho_M_scale_-1:0' shape=() dtype=float32, numpy=-2.2521684>,\n",
       " <tf.Variable 'lambda_M_loc_-1:0' shape=() dtype=float32, numpy=2.9489307>,\n",
       " <tf.Variable 'lambda_M_scale_-1:0' shape=() dtype=float32, numpy=0.54132485>,\n",
       " <tf.Variable 'nu_M_loc_-1:0' shape=() dtype=float32, numpy=4.9932394>,\n",
       " <tf.Variable 'nu_M_scale_-1:0' shape=() dtype=float32, numpy=0.8416177>,\n",
       " <tf.Variable 'warmup_A_loc_0_-1:0' shape=() dtype=float32, numpy=2000.0>,\n",
       " <tf.Variable 'warmup_A_scale_0_-1:0' shape=() dtype=float32, numpy=500.0>,\n",
       " <tf.Variable 'warmup_A_loc_1_-1:0' shape=() dtype=float32, numpy=2000.0>,\n",
       " <tf.Variable 'warmup_A_scale_1_-1:0' shape=() dtype=float32, numpy=500.0>,\n",
       " <tf.Variable 'warmup_A_loc_2_-1:0' shape=() dtype=float32, numpy=2000.0>,\n",
       " <tf.Variable 'warmup_A_scale_2_-1:0' shape=() dtype=float32, numpy=500.0>,\n",
       " <tf.Variable 'warmup_A_loc_3_-1:0' shape=() dtype=float32, numpy=2000.0>,\n",
       " <tf.Variable 'warmup_A_scale_3_-1:0' shape=() dtype=float32, numpy=500.0>,\n",
       " <tf.Variable 'warmup_A_loc_4_-1:0' shape=() dtype=float32, numpy=2000.0>,\n",
       " <tf.Variable 'warmup_A_scale_4_-1:0' shape=() dtype=float32, numpy=500.0>,\n",
       " <tf.Variable 'warmup_A_loc_5_-1:0' shape=() dtype=float32, numpy=2000.0>,\n",
       " <tf.Variable 'warmup_A_scale_5_-1:0' shape=() dtype=float32, numpy=500.0>,\n",
       " <tf.Variable 'warmup_A_loc_6_-1:0' shape=() dtype=float32, numpy=2000.0>,\n",
       " <tf.Variable 'warmup_A_scale_6_-1:0' shape=() dtype=float32, numpy=500.0>,\n",
       " <tf.Variable 'warmup_A_loc_7_-1:0' shape=() dtype=float32, numpy=2000.0>,\n",
       " <tf.Variable 'warmup_A_scale_7_-1:0' shape=() dtype=float32, numpy=500.0>,\n",
       " <tf.Variable 'warmup_A_loc_8_-1:0' shape=() dtype=float32, numpy=2000.0>,\n",
       " <tf.Variable 'warmup_A_scale_8_-1:0' shape=() dtype=float32, numpy=500.0>,\n",
       " <tf.Variable 'warmup_A_loc_9_-1:0' shape=() dtype=float32, numpy=2000.0>,\n",
       " <tf.Variable 'warmup_A_scale_9_-1:0' shape=() dtype=float32, numpy=500.0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1022303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variables = model.variables[:-2*transition_window]\n",
    "assert all(['warmup' not in variable.name for variable in model_variables])\n",
    "warmup_variables = model.variables[-2*transition_window:]\n",
    "assert all(['warmup' in variable.name for variable in warmup_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87a9c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = LogPoissonProb() \n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=1, #beta_1=0.1, beta_2=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "423d66f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_callbacks = get_logging_callbacks('/mnt/c/Users/kheut/logs/covid/bayes_learn_all_estim_flex_warm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c8368b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 23688.6562\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 7319.5581\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 6615.1787\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 7845.7778\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 8718.6904\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 9056.5107\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 8185.9512\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 7364.6680\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 7470.7769\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 7949.6587\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 8420.8369\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 7989.4761\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 8342.8721\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 7744.9629\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 7192.3491\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 23s 23s/step - loss: 7203.5728\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 7292.6987\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 7410.1040\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 8206.0166\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 23s 23s/step - loss: 7598.5449\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 7855.8145\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 22s 22s/step - loss: 7409.1069\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 23s 23s/step - loss: 7388.7480\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 24s 24s/step - loss: 7347.3184\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 7122.7197\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 32s 32s/step - loss: 7399.2451\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 37s 37s/step - loss: 7224.9780\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 7405.3105\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 20s 20s/step - loss: 7559.9023\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 6671.7134\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 7020.7495\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 28s 28s/step - loss: 7320.9429\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 6513.5884\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 22s 22s/step - loss: 6805.6431\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 6721.3921\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 6362.1304\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 20s 20s/step - loss: 6620.7168\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 22s 22s/step - loss: 6534.1479\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 6534.2305\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 20s 20s/step - loss: 6439.1963\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 5957.3467\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 6026.8013\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 5811.6899\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 5776.0820\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 5448.0332\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 4637.2920\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 4802.7427\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 5247.0620\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 5072.9824\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 4870.8848\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 5250.7256\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 4948.6870\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 5437.1318\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 4606.9824\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 4603.5615\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 4709.7642\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 4697.2563\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 4828.4819\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 4801.5791\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 20s 20s/step - loss: 4523.7222\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 23s 23s/step - loss: 4846.1362\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 4766.2358\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 4820.1094\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 4695.6362\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 4212.4014\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 4641.5049\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 4367.1147\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 4499.2197\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 4357.8232\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 30s 30s/step - loss: 4393.1138\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 4593.9761\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 4341.2642\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 4228.8447\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 20s 20s/step - loss: 4493.2720\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 4585.4629\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 23s 23s/step - loss: 4069.4924\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 4068.7290\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 23s 23s/step - loss: 4137.5181\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 4198.3965\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 24s 24s/step - loss: 4175.7046\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 4562.7153\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 3865.3953\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 4315.7090\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 4275.8584\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 4262.4175\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 4102.3975\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 4133.8237\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 4077.6731\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 4103.8687\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 4248.0815\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3973.0688\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 4038.2039\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 4143.1016\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 4073.8806\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 4147.4058\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 21s 21s/step - loss: 4090.3921\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 22s 22s/step - loss: 3999.8591\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 4016.0840\n",
      "Epoch 99/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 18s 18s/step - loss: 3997.7170\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 3705.6750\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 3956.2356\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 4119.2305\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 3997.6880\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 20s 20s/step - loss: 4026.0195\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 3848.1169\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 3797.1189\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 3788.0220\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 3904.7461\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 3924.0874\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 3954.9485\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 4109.4048\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 3629.4868\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 3654.1987\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3654.8840\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3608.5540\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3541.9241\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3643.9141\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 3755.4712\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 3576.5452\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 4083.1023\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 3557.9480\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 3666.0159\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 3430.1841\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 3652.4141\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 3548.0867\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3592.9822\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 3816.9807\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 3616.7712\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 3679.4460\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 3573.7612\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 3451.4402\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 3643.5403\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3312.8113\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3622.3252\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3455.2976\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3485.7126\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3373.7554\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3463.3711\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3465.7795\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3456.1396\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3234.8113\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3110.9973\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3311.0547\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3274.4407\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3370.3489\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3137.0112\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3406.4507\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3236.6616\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 3191.2073\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3146.6509\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3240.1733\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 3117.8708\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3143.9126\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3176.1677\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3456.6074\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 3269.6057\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3161.0420\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3308.7893\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2962.1443\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2976.1226\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3142.2937\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3084.3440\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3302.3252\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3159.1538\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3223.6401\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 3187.1531\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3017.4104\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3055.0505\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3005.4790\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3184.1018\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3338.8740\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2984.6587\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 2769.6423\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2822.0708\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2813.8218\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2811.4463\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 2902.7087\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2813.4912\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2771.7759\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2977.7146\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2814.5752\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 3082.8643\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2975.6985\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2789.2947\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2803.2068\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2939.2678\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2781.2722\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2745.4541\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2680.4404\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2672.2522\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2780.2498\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2947.3059\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2717.5747\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2821.1951\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2765.5562\n",
      "Epoch 196/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 14s 14s/step - loss: 2693.8206\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2551.7488\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 2673.5959\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 2985.0793\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 2603.4482\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 2675.4114\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 2568.7712\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 2806.7532\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 2563.2756\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 2539.7781\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 2546.1987\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2577.6653\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 2671.4756\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 2603.0767\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 22s 22s/step - loss: 2620.5920\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 2636.4800\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 2617.3281\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2758.8882\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2425.4609\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 2406.8467\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 2417.2715\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 2325.1479\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 2314.1919\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 2445.2952\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 2435.7424\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2510.4009\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2466.0073\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2542.0427\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2443.7544\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2331.8296\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2540.2930\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2508.5037\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2386.6250\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2601.1040\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2403.2478\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2277.6917\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2210.3428\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2403.1716\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2321.6455\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2382.8340\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2286.5251\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 2409.9504\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2172.3293\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2218.2024\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2314.1001\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 2349.3064\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 2204.3125\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 2224.9182\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 25s 25s/step - loss: 2277.7444\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 2328.8274\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 23s 23s/step - loss: 2360.3181\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 2236.5750\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2198.1106\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2012.4375\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 2284.3984\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 22s 22s/step - loss: 2291.4006\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 2085.6704\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 2058.1348\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 2279.8770\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 2236.4221\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 39s 39s/step - loss: 2038.5350\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 25s 25s/step - loss: 2136.6255\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 2241.2769\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2099.6926\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 2113.4968\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 2172.1199\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 22s 22s/step - loss: 2149.0952\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 2072.8035\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 2100.9995\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 2048.4526\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 2097.1399\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 2110.2410\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 1886.9099\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 27s 27s/step - loss: 1986.2480\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 1939.1123\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 2029.0306\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 2060.7366\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 22s 22s/step - loss: 2083.5833\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 2046.4623\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2029.6666\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 1968.1464\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 2078.2283\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 1966.6512\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 1876.3152\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 1956.3552\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 1919.9551\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 1859.4857\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 14s 14s/step - loss: 1875.7449\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1828.6549\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 1904.7435\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 1996.6265\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 1946.5603\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 1876.2574\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 1787.1266\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1984.4456\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 1898.1058\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1859.1431\n",
      "Epoch 293/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 15s 15s/step - loss: 1856.8376\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1979.1079\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1847.6503\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1900.9542\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 22s 22s/step - loss: 1863.4999\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 1845.0251\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1948.9186\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1845.0209\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1919.8922\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 1878.4763\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1851.3322\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 1895.7914\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1835.9906\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 21s 21s/step - loss: 1887.1616\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 1772.8914\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 1724.3214\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 27s 27s/step - loss: 1722.2654\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 25s 25s/step - loss: 1871.1125\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1801.8918\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 32s 32s/step - loss: 1831.0048\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 23s 23s/step - loss: 1788.5957\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1777.3134\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 26s 26s/step - loss: 1676.9877\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 1789.2229\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 19s 19s/step - loss: 1652.0383\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1813.4940\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1727.5802\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1633.2836\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1687.4434\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1779.5685\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1675.2563\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1644.3434\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1673.4116\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1681.9519\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 22s 22s/step - loss: 1652.3083\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 1714.5653\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 1636.1929\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 1639.5493\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 40s 40s/step - loss: 1611.1576\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 17s 17s/step - loss: 1664.1830\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1721.5361\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1581.7878\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 16s 16s/step - loss: 1649.2046\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1666.6256\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 18s 18s/step - loss: 1593.9338\n",
      "Epoch 338/500\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=loss, optimizer=optimizer, run_eagerly=True)\n",
    "model.fit(x=np.asarray([x_train]), y=np.asarray([y_test]),\n",
    "         epochs=500, batch_size=0,\n",
    "        callbacks=logging_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910c2f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "preds=tf.reduce_mean(model.call(x_train), axis=-1)\n",
    "plt.plot(df.loc[train_start:test_end].index.values, y_test, label='CovidEstim Mild')\n",
    "plt.plot(df.loc[train_start:test_end].index.values, preds, label='Predicted Mild')\n",
    "month_ticks = matplotlib.dates.MonthLocator(interval=1)\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(month_ticks)\n",
    "plt.legend()\n",
    "plt.title('Mild Compartment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e61f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "preds=tf.reduce_mean(model.call(x_train), axis=-1)\n",
    "plt.plot(df.loc[train_start:test_end].index.values, y_test, label='CovidEstim Mild')\n",
    "plt.plot(df.loc[train_start:test_end].index.values, pre_training_preds, label='Predicted Before Training Mild')\n",
    "month_ticks = matplotlib.dates.MonthLocator(interval=1)\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(month_ticks)\n",
    "plt.legend()\n",
    "plt.title('Mild Compartment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438fbf19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdd92d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7790428a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f44042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tfa.optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cf260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8*2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9478d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_asymp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86caf2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_mild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e20272",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdad1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[warmup_start:'20210510','mild']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdec032",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_asymp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13a5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8313b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_model = copy.deepcopy(model)\n",
    "copy_model.unconstrained_warmup_A_params[-1][2]['loc'] = tf.Variable(2500.0, dtype=tf.float32)\n",
    "copy_model.unconstrained_warmup_A_params[-1][1]['loc'] = tf.Variable(2500.0, dtype=tf.float32)\n",
    "copy_model.unconstrained_warmup_A_params[-1][0]['loc'] = tf.Variable(2500.0, dtype=tf.float32)\n",
    "copy_model.unconstrained_nu_M[-1]['loc'] = tf.Variable(3.0, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e6ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "copy_preds=tf.reduce_mean(copy_model.call(x_train), axis=-1)\n",
    "plt.plot(df.loc[train_start:test_end].index.values, y_test, label='CovidEstim Mild')\n",
    "plt.plot(df.loc[train_start:test_end].index.values, copy_preds, label='Predicted Mild')\n",
    "month_ticks = matplotlib.dates.MonthLocator(interval=1)\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(month_ticks)\n",
    "plt.legend()\n",
    "plt.title('Mild Compartment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb5613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(y_test, copy_model.call(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a7f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_model.unconstrained_nu_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f648a7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_model.unconstrained_rho_M[-1]['loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc0824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.sigmoid(1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef7bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_A_params[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e930c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_asymp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37263281",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_mild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148b9927",
   "metadata": {},
   "outputs": [],
   "source": [
    "1800/2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9128e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "copy_preds=tf.reduce_mean(copy_model.call(x_train), axis=-1)\n",
    "plt.plot(df.loc[train_start:test_end].index.values, df.loc[train_start:test_end, 'mild']/df.loc[train_start:test_end, 'asymp'], label='Asymp/Mild')\n",
    "#plt.plot(df.loc[train_start:test_end].index.values, preds, label='Predicted Mild')\n",
    "month_ticks = matplotlib.dates.MonthLocator(interval=1)\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(month_ticks)\n",
    "plt.legend()\n",
    "plt.title('Empirical Rho_M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e6cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.96**(1/5.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c21262",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_asymp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc73fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c2f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.T_serial_samples_constrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e263a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_model.call(x_train,return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84283817",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_asymp*x_train[2] ** (1/model.T_serial_samples_constrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b375b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_model.warmup_A_samples[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aeff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc81004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
